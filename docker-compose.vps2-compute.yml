version: '3.8'

# ============================================================================
# VPS2 - AI & Compute Backend (Hetzner 8c/16GB)
# ============================================================================
#
# Services:
# - LiteLLM (universal LLM proxy with AWS S3 cache)
# - MetaMCP (MCP server registry)
# - Chroma (vector database for embeddings)
# - LibreChat (chat UI for case building)
# - Open WebUI (alternative chat UI)
# - Ollama (local model routing)
# - Kasm Workspace (remote desktop for CLI tools)
# - Browserless + Playwright (headless browsers)
# - Tailscale sidecar (VPN)
#
# Storage strategy:
# - AWS S3 free tier (5GB): LiteLLM cache
# - Local volumes: Chroma, Ollama models
# - PostgreSQL on VPS1 (via Tailnet)
#
# Deploy: docker-compose -f docker-compose.vps2-compute.yml up -d
#
# ============================================================================

networks:
  salem-network:
    driver: bridge
  traefik:
    external: true

volumes:
  chroma_data:
  metamcp_data:
  ollama_data:
  open_webui_data:
  kasm_home:
  kasm_config:
  playwright_cache:
  tailscale_data:

services:
  # ============================================================================
  # Infrastructure Sidecar - Tailscale VPN
  # ============================================================================
  infrastructure:
    image: alpine:latest
    container_name: salem-vps2-infrastructure
    hostname: salem-compute
    privileged: true
    cap_add:
      - NET_ADMIN
    devices:
      - /dev/net/tun
    environment:
      - TS_AUTHKEY=${TAILSCALE_AUTH_KEY}
      - TS_STATE_DIR=/var/lib/tailscale
      - TS_USERSPACE=false
      - TS_EXTRA_ARGS=--advertise-tags=tag:salem-compute
    volumes:
      - tailscale_data:/var/lib/tailscale
      - /dev/net/tun:/dev/net/tun
    command: |
      sh -c "
        # Install Tailscale
        apk add --no-cache tailscale
        
        # Start Tailscale
        tailscaled --state=/var/lib/tailscale/tailscaled.state --socket=/var/run/tailscale/tailscaled.sock &
        sleep 5
        tailscale up --authkey=\$TS_AUTHKEY \$TS_EXTRA_ARGS
        
        # Keep running
        tail -f /dev/null
      "
    restart: unless-stopped
    networks:
      - salem-network
    deploy:
      resources:
        limits:
          memory: 128M
    labels:
      - "coolify.managed=true"
      - "coolify.type=infrastructure"

  # ============================================================================
  # Chroma - Vector Database
  # ============================================================================
  chroma:
    image: chromadb/chroma:latest
    container_name: salem-chroma
    environment:
      - CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=chromadb.auth.token.TokenConfigServerAuthCredentialsProvider
      - CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER=X-Chroma-Token
      - CHROMA_SERVER_AUTH_CREDENTIALS=${CHROMA_AUTH_TOKEN}
      - IS_PERSISTENT=TRUE
      - ANONYMIZED_TELEMETRY=FALSE
    volumes:
      - chroma_data:/chroma/chroma
    restart: unless-stopped
    networks:
      - salem-network
      - traefik
    deploy:
      resources:
        limits:
          memory: 2G
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.chroma.rule=Host(`chroma.${DOMAIN}`)"
      - "traefik.http.routers.chroma.entrypoints=websecure"
      - "traefik.http.routers.chroma.tls.certresolver=letsencrypt"
      - "traefik.http.services.chroma.loadbalancer.server.port=8000"
      - "coolify.managed=true"
      - "coolify.type=database"

  # ============================================================================
  # LiteLLM - Universal LLM Proxy with S3 Cache
  # ============================================================================
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: salem-litellm
    environment:
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY}
      - LITELLM_LOG=INFO
      - LITELLM_DROP_PARAMS=true
      # AWS S3 cache (5GB free tier)
      - LITELLM_CACHE=s3
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION:-us-east-1}
      - S3_BUCKET_NAME=${S3_CACHE_BUCKET:-salem-litellm-cache}
      # LLM API keys
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - COHERE_API_KEY=${COHERE_API_KEY}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - GROQ_API_KEY=${GROQ_API_KEY}
    volumes:
      - ./litellm_config.yaml:/app/config.yaml:ro
    command: --config /app/config.yaml --port 4000 --num_workers 4
    restart: unless-stopped
    networks:
      - salem-network
      - traefik
    deploy:
      resources:
        limits:
          memory: 2G
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.litellm.rule=Host(`llm.${DOMAIN}`)"
      - "traefik.http.routers.litellm.entrypoints=websecure"
      - "traefik.http.routers.litellm.tls.certresolver=letsencrypt"
      - "traefik.http.services.litellm.loadbalancer.server.port=4000"
      - "coolify.managed=true"
      - "coolify.type=service"

  # ============================================================================
  # MetaMCP - MCP Server Registry
  # ============================================================================
  metamcp:
    build:
      context: .
      dockerfile: Dockerfile.metamcp
    container_name: salem-metamcp
    environment:
      - PORT=4001
      - POSTGRES_URL=postgres://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD}@salem-storage:5432/${POSTGRES_DB:-salem}
      - MCP_REGISTRY_URL=https://mcp.run/registry
    volumes:
      - ./server/mcp:/app/mcp:ro
      - metamcp_data:/app/data
    restart: unless-stopped
    networks:
      - salem-network
      - traefik
    deploy:
      resources:
        limits:
          memory: 512M
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.metamcp.rule=Host(`mcp.${DOMAIN}`)"
      - "traefik.http.routers.metamcp.entrypoints=websecure"
      - "traefik.http.routers.metamcp.tls.certresolver=letsencrypt"
      - "traefik.http.services.metamcp.loadbalancer.server.port=4001"
      - "coolify.managed=true"
      - "coolify.type=service"

  # ============================================================================
  # LibreChat - Multi-Model Chat UI for Case Building
  # ============================================================================
  librechat:
    image: ghcr.io/danny-avila/librechat:latest
    container_name: salem-librechat
    environment:
      - HOST=0.0.0.0
      - PORT=3080
      # FerretDB on VPS1 (via Tailnet)
      - MONGO_URI=mongodb://salem-storage:27017/LibreChat
      # LiteLLM proxy
      - OPENAI_API_KEY=${LITELLM_MASTER_KEY}
      - OPENAI_REVERSE_PROXY=http://litellm:4000/v1
      - ANTHROPIC_API_KEY=${LITELLM_MASTER_KEY}
      - ANTHROPIC_REVERSE_PROXY=http://litellm:4000/v1
    restart: unless-stopped
    networks:
      - salem-network
      - traefik
    deploy:
      resources:
        limits:
          memory: 2G
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.librechat.rule=Host(`chat.${DOMAIN}`)"
      - "traefik.http.routers.librechat.entrypoints=websecure"
      - "traefik.http.routers.librechat.tls.certresolver=letsencrypt"
      - "traefik.http.services.librechat.loadbalancer.server.port=3080"
      - "coolify.managed=true"
      - "coolify.type=application"

  # ============================================================================
  # Open WebUI - Alternative Chat UI
  # ============================================================================
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: salem-open-webui
    environment:
      - WEBUI_SECRET_KEY=${OPENWEBUI_SECRET_KEY}
      - WEBUI_NAME=Salem Forensics AI
      - OPENAI_API_KEY=${LITELLM_MASTER_KEY}
      - OPENAI_API_BASE_URL=http://litellm:4000/v1
      - OLLAMA_BASE_URL=http://ollama:11434
      - ENABLE_RAG=true
      - ENABLE_SIGNUP=false
    volumes:
      - open_webui_data:/app/backend/data
    depends_on:
      - ollama
    restart: unless-stopped
    networks:
      - salem-network
      - traefik
    deploy:
      resources:
        limits:
          memory: 1G
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.openwebui.rule=Host(`ui.${DOMAIN}`)"
      - "traefik.http.routers.openwebui.entrypoints=websecure"
      - "traefik.http.routers.openwebui.tls.certresolver=letsencrypt"
      - "traefik.http.services.openwebui.loadbalancer.server.port=8080"
      - "coolify.managed=true"
      - "coolify.type=application"

  # ============================================================================
  # Ollama - Local LLM Runtime (routing only, no local models)
  # ============================================================================
  ollama:
    image: ollama/ollama:latest
    container_name: salem-ollama
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    networks:
      - salem-network
      - traefik
    deploy:
      resources:
        limits:
          memory: 512M
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.ollama.rule=Host(`ollama.${DOMAIN}`)"
      - "traefik.http.routers.ollama.entrypoints=websecure"
      - "traefik.http.routers.ollama.tls.certresolver=letsencrypt"
      - "traefik.http.services.ollama.loadbalancer.server.port=11434"
      - "coolify.managed=true"
      - "coolify.type=service"

  # ============================================================================
  # Kasm Workspace - Remote Desktop with AI CLI Tools
  # ============================================================================
  kasm-workspace:
    build:
      context: .
      dockerfile: Dockerfile.kasm
    container_name: salem-kasm-workspace
    environment:
      - VNC_PW=${KASM_VNC_PASSWORD}
      - VNC_RESOLUTION=1920x1080
      - VNC_COL_DEPTH=24
      - CLAUDE_API_KEY=${ANTHROPIC_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
    volumes:
      - kasm_home:/home/kasm-user
      - kasm_config:/home/kasm-user/.config
      - ./scripts:/scripts:ro
    shm_size: 2gb
    restart: "no"
    networks:
      - salem-network
      - traefik
    deploy:
      resources:
        limits:
          memory: 4G
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.kasm.rule=Host(`desktop.${DOMAIN}`)"
      - "traefik.http.routers.kasm.entrypoints=websecure"
      - "traefik.http.routers.kasm.tls.certresolver=letsencrypt"
      - "traefik.http.services.kasm.loadbalancer.server.port=6901"
      - "coolify.managed=true"
      - "coolify.type=application"
      - "n8n.service=on-demand"
      - "n8n.priority=low"
      # Access: Primary via Tailscale (http://salem-compute:6901)
      # Backup via Cloudflare Access (https://desktop.mitechconsult.com)

  # ============================================================================
  # Browserless - Headless Chrome
  # ============================================================================
  browserless:
    image: browserless/chrome:latest
    container_name: salem-browserless
    environment:
      - TOKEN=${BROWSERLESS_TOKEN}
      - MAX_CONCURRENT_SESSIONS=2
      - CONNECTION_TIMEOUT=60000
      - MAX_QUEUE_LENGTH=5
      - ENABLE_DEBUGGER=true
      - PREBOOT_CHROME=false
    restart: "no"
    networks:
      - salem-network
      - traefik
    deploy:
      resources:
        limits:
          memory: 1G
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.browserless.rule=Host(`browser.${DOMAIN}`)"
      - "traefik.http.routers.browserless.entrypoints=websecure"
      - "traefik.http.routers.browserless.tls.certresolver=letsencrypt"
      - "traefik.http.services.browserless.loadbalancer.server.port=3000"
      - "coolify.managed=true"
      - "coolify.type=service"
      - "n8n.service=on-demand"

  # ============================================================================
  # Playwright - Headless Browser Automation
  # ============================================================================
  playwright:
    build:
      context: .
      dockerfile: Dockerfile.playwright
    container_name: salem-playwright
    environment:
      - PLAYWRIGHT_BROWSERS_PATH=/ms-playwright
    volumes:
      - playwright_cache:/ms-playwright
      - ./scripts/playwright:/scripts:ro
    restart: "no"
    networks:
      - salem-network
      - traefik
    deploy:
      resources:
        limits:
          memory: 512M
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.playwright.rule=Host(`playwright.${DOMAIN}`)"
      - "traefik.http.routers.playwright.entrypoints=websecure"
      - "traefik.http.routers.playwright.tls.certresolver=letsencrypt"
      - "traefik.http.services.playwright.loadbalancer.server.port=3000"
      - "coolify.managed=true"
      - "coolify.type=service"
      - "n8n.service=on-demand"
